{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "`Customer churn`` occurs when customers stop doing business with a company, also known as customer attrition. It is also referred to as loss of clients or customers.\n",
    "\n",
    "Imagine the following data set contains sensitive information of 9,000 of a European Bank, EBQ. Using an Artificial Neural Network (ANN) based on the dataset we will attempt to correctly predict who is going to leave next.\n",
    "Here is a breakdown of the features in the dataset\n",
    "\n",
    "* `CustomerId`: a unique identifier for each customer within the dataset. These values are not ordered sequentially within the dataset, and are only used to identify a specific customer. It typically does not have any influence to whether a customer leaves the business.\n",
    "* `Surname`: A string used to identify the customer in the dataset. Surname may be distinct amidst all or most customers. Because of this, it most likely won't affect the target variable. \n",
    "* `CreditScore`: a numeric representation of the customer's individual fiscal credit score. Typically used to indicate eligibility for loans. Current credit scores use a range from 300 to 850, but the FICO auto score range uses 250-900. This feature likely determines retention rate of customers. \n",
    "* `Geography`: this feature contains a categorical string representing the name of a country the customer is from originally. \n",
    "* `Gender`: this feature contains a categorical string representing the gender of the customer (\"Male\"/\"Female\"). \n",
    "* `Age`: a numerical integer representation of a customer's age. Intuition suggests that older customers are likely to have higher retention than younger customers.\n",
    "* `Tenure`: a numerical integer representation. It is assumed that this feature represents the number of total years the customer has been retained. It is likely that customers which have been retained longer will continue to be retained.\n",
    "* `Balance`: a numerical floating point number (to two decimal places of precision) indicating the customer's current bank balance (assumed total across all accounts). Customers with a greater balance may be less likely to exit the account due to difficulty of transfer. \n",
    "* `NumOfProducts`: numeric integer value. It is assumed that this value represents the number of accounts (products) that this customer has open. Further evaluation of this feature would be needed to determine the usefulness of this feature, but at face-value, intuition dictates that a customer with more products is less likely to exit. \n",
    "* `HasCrCard`: boolean flag (0 or 1) representing whether the customer has a credit card or not. \n",
    "* `IsActiveMember`: boolean flag (0 or 1) representing whether the customer is an active member of the bank. It is assumed this indicates whether the customer has transactions on the regular banking statement. Intuition dictates that inactive members are more likely to exit. \n",
    "* `EstimatedSalary`: numerical floating point representation of the customer's predicted salary (to two decomal places) intuition dictates that customers with different incomes may behave differently with respect to retention rate. \n",
    "* `Exited`: boolean flag (0 or 1) representing whether the customer has exited their account. This is the target variable for the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Summary\n",
    "* The following function reads the dataset from a file, constructs the dataframe in pandas and provides a summary of much of the relevant data giving a brief overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T18:11:20.934979500Z",
     "start_time": "2023-10-05T18:11:17.348652100Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import keras\n",
    "from keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T18:11:20.971155600Z",
     "start_time": "2023-10-05T18:11:20.934979500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of rows =  9000\n",
      "total number of columns =  13\n",
      "number of columns having non-numeric values = 3\n",
      "columns with missing values = [('Age', 397), ('CreditScore', 26)]\n",
      "gender based summary of exited column = [('Female', '24.77%'), ('Male', '16.63%')]\n",
      "age based summary of exited column = [('below or equal to 40', '10.94%'), ('above 40', '37.63%')]\n",
      "credit score summary = 650.25 +/- 96.75\n"
     ]
    }
   ],
   "source": [
    "def summarize_dataset(csv_file):\n",
    "    data_set = pd.read_csv(csv_file)\n",
    "    # Count and print the number of rows\n",
    "    a = len(data_set.index)\n",
    "    print('total number of rows =  %d' % a)\n",
    "    # Count and print the number of columns\n",
    "    b = len(data_set.columns)\n",
    "    print('total number of columns =  %d' % b)\n",
    "    # The describe function drops the non-numerical columns, subtract this from the total number\n",
    "    c = b - len(data_set.describe().columns)\n",
    "    print('number of columns having non-numeric values = %d' % c)\n",
    "    missing_data_tuples = []\n",
    "    # Loop through the columns, if a column contains missing values note that column and sum the number of missing values\n",
    "    for column in data_set:\n",
    "        if data_set[column].isna().sum() > 0:\n",
    "            d = column\n",
    "            e = data_set[column].isna().sum()\n",
    "            missing_data_tuples.append((d, e))\n",
    "    missing_data_tuples = sorted(missing_data_tuples, key=lambda x: (x[1], x[1]), reverse=True)\n",
    "    print('columns with missing values = {0}'.format(missing_data_tuples))\n",
    "    f1 = 'Male'\n",
    "    f2 = 'Female'\n",
    "    # Divide the number of each gender who exited by the total number of each gender\n",
    "    g1 = len(data_set[(data_set['Gender'] == f1) & data_set['Exited'] == 1]) / len(data_set[data_set['Gender'] == f1])\n",
    "    g2 = len(data_set[(data_set['Gender'] == f2) & data_set['Exited'] == 1]) / len(data_set[data_set['Gender'] == f2])\n",
    "    g1 = f'{g1:.2%}'\n",
    "    g2 = f'{g2:.2%}'\n",
    "    gen_exit = [(f1, g1), (f2, g2)]\n",
    "    gen_exit = sorted(gen_exit, key=lambda x: (x[1], x[1]), reverse=True)\n",
    "    print('gender based summary of exited column = {}'.format(gen_exit))\n",
    "    # Divide the number of those in each age group who exited by the total number of each age group\n",
    "    h1 = len(data_set[(data_set['Age'] <= 40) & data_set['Exited'] == 1]) / len(data_set[data_set['Age'] <= 40])\n",
    "    h2 = len(data_set[(data_set['Age'] > 40) & data_set['Exited'] == 1]) / len(data_set[data_set['Age'] > 40])\n",
    "    h1 = f'{h1:.2%}'\n",
    "    h2 = f'{h2:.2%}'\n",
    "    age_exit = [('below or equal to 40', h1), ('above 40', h2)]\n",
    "    print('age based summary of exited column = {}'.format(age_exit))\n",
    "    # Calculate the mean and standard deviation\n",
    "    i = data_set['CreditScore'].mean()\n",
    "    j = data_set['CreditScore'].std()\n",
    "    print('credit score summary = %.2f +/- %.2f' % (i, j))\n",
    "    return data_set\n",
    "dataset = summarize_dataset('dataset/datasetX.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preproccessing of the data before training the ANN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-247a930d79bde8e3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2023-10-05T18:11:20.983265300Z",
     "start_time": "2023-10-05T18:11:20.967148700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Drop irrelevant data columns\n",
    "dataset_dropped = dataset.drop(['CustomerId', 'Surname'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "shuff_dataset_final",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2023-10-05T18:11:21.030981100Z",
     "start_time": "2023-10-05T18:11:20.983265300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Shuffle the dataset based on the provided seed\n",
    "dataset_shuffled = dataset_dropped.sample(frac=1, random_state=4321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T18:11:21.047119Z",
     "start_time": "2023-10-05T18:11:20.999283Z"
    }
   },
   "outputs": [],
   "source": [
    "# Divide data into x and y values\n",
    "X = dataset_shuffled.drop(['Exited'], axis=1)\n",
    "y = dataset_shuffled['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "train_test_split",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2023-10-05T18:11:21.047119Z",
     "start_time": "2023-10-05T18:11:21.014972200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split and shuffle the dataset into appropriate groups\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=4321, test_size=.20, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "one-hot-encoding-function",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2023-10-05T18:11:21.047119Z",
     "start_time": "2023-10-05T18:11:21.030981100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Perform the One Hot Encoding on the training set using the scikitlearn OneHotEncoder and use that encoding to OHE the test set\n",
    "# Drop the first generated column for each OHE category to avoid the dummy variable trap and fit the dataset within the required 11 variable input for the model\n",
    "enc = OneHotEncoder(sparse_output=False, drop='first')\n",
    "columns_to_one_hot = ['Geography', 'Gender']\n",
    "encoded_array = enc.fit_transform(X_train.loc[:,columns_to_one_hot])\n",
    "df_encoded = pd.DataFrame(encoded_array, columns=enc.get_feature_names_out())\n",
    "X_train_ohe = pd.concat([X_train.reset_index(drop=True), df_encoded.reset_index(drop=True)],axis=1)\n",
    "X_train_ohe.drop(labels=columns_to_one_hot, axis=1, inplace=True)\n",
    "\n",
    "enc.transform(X_test.loc[:,columns_to_one_hot])\n",
    "encoded_array = enc.transform(X_test.loc[:,columns_to_one_hot])\n",
    "df_encoded_2 = pd.DataFrame(encoded_array, columns=enc.get_feature_names_out())\n",
    "X_test_ohe = pd.concat([X_test.reset_index(drop=True), df_encoded_2.reset_index(drop=True)], axis=1)\n",
    "X_test_ohe.drop(labels=columns_to_one_hot,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "normalizer-learning-training",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2023-10-05T18:11:21.094762Z",
     "start_time": "2023-10-05T18:11:21.047119Z"
    }
   },
   "outputs": [],
   "source": [
    "def normalize_data(df):\n",
    "    for column in df.columns:\n",
    "        df[column] = (df[column] - df[column].mean()) / df[column].std()\n",
    "        df[column].fillna(df[column].median(), inplace=True)\n",
    "    return df\n",
    "X_train_scaled = normalize_data(X_train_ohe)\n",
    "X_test_scaled = normalize_data(X_test_ohe)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing and validation\n",
    "Here are three different ANN architectures used to make predictions based on the dataset.\n",
    "After training and testing the model we will also use the model to make a single prediction for one element in the test set where we know the Exited value and one where we do not and attempt to draw conclusions based on the features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## First ANN Architecture\n",
    "  ![Display Network Architecture](figs/nn-1.png)\n",
    "  * **Input layer** will have 11 units as the dimension of training set: `X_train_scaled` (i.e, number of columns = 11).\n",
    "  * **First hidden layer** will have 5 neurons, each with \"Rectified Linear Unit (`ReLU``)\" as activation function.\n",
    "  * **Second hidden layer** will have 4 neurons, each with \"`ReLU`\" as activation function.\n",
    "  * **Output layer** will have just 1 neuron, with `sigmoid`` activation function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T18:11:21.094762Z",
     "start_time": "2023-10-05T18:11:21.062724700Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "known_test_x and unknown_test_x are selected from the scaled dataset using an index to have scaled and normalized data.\n",
    "known_test_inspect and unknown_test_inspect are the same elements from the dataset selected using the same index but they\n",
    "relate to the data before it has been normalized so it is easier to draw conclusions via visual inspection\n",
    "\"\"\"\n",
    "known_test_x = pd.DataFrame(X_test_scaled.loc[100])\n",
    "known_test_inspect = pd.DataFrame(X_test.iloc[100])\n",
    "known_test_x =  known_test_x.transpose()\n",
    "known_test_y = y_test.iloc[100]\n",
    "unknown_test_x = pd.DataFrame(X_test_scaled.loc[928])\n",
    "unknown_test_inspect = pd.DataFrame(X_test.iloc[928])\n",
    "unknown_test_x = unknown_test_x.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "ANN-1_layers",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2023-10-05T18:11:31.639230Z",
     "start_time": "2023-10-05T18:11:21.078749300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "225/225 [==============================] - 2s 1ms/step - loss: 0.7117 - accuracy: 0.5512\n",
      "Epoch 2/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.5011 - accuracy: 0.7953\n",
      "Epoch 3/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4699 - accuracy: 0.7962\n",
      "Epoch 4/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4542 - accuracy: 0.7961\n",
      "Epoch 5/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4433 - accuracy: 0.7974\n",
      "Epoch 6/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4341 - accuracy: 0.8025\n",
      "Epoch 7/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4240 - accuracy: 0.8122\n",
      "Epoch 8/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4147 - accuracy: 0.8175\n",
      "Epoch 9/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4075 - accuracy: 0.8251\n",
      "Epoch 10/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4016 - accuracy: 0.8263\n",
      "Epoch 11/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.3973 - accuracy: 0.8276\n",
      "Epoch 12/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.3937 - accuracy: 0.8289\n",
      "Epoch 13/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.3906 - accuracy: 0.8297\n",
      "Epoch 14/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.3878 - accuracy: 0.8311\n",
      "Epoch 15/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.3854 - accuracy: 0.8326\n",
      "Epoch 16/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.3830 - accuracy: 0.8329\n",
      "Epoch 17/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.3810 - accuracy: 0.8335\n",
      "Epoch 18/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.3792 - accuracy: 0.8332\n",
      "Epoch 19/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.3773 - accuracy: 0.8339\n",
      "Epoch 20/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.3758 - accuracy: 0.8322\n",
      "Epoch 21/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.3741 - accuracy: 0.8331\n",
      "Epoch 22/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.3727 - accuracy: 0.8346\n",
      "Epoch 23/25\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3713 - accuracy: 0.8340\n",
      "Epoch 24/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.3702 - accuracy: 0.8494\n",
      "Epoch 25/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.3690 - accuracy: 0.8500\n"
     ]
    }
   ],
   "source": [
    "# Creating first model based on an 11 input follow by 5 node and 4 node hidden layers and 1 output node\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(5, activation='relu', input_shape=(11,)))\n",
    "model.add(layers.Dense(4, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train_scaled, y_train, epochs=25)\n",
    "model.save('saved_models/model-ann-11-5-4-1.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T18:11:31.654482700Z",
     "start_time": "2023-10-05T18:11:31.639230Z"
    }
   },
   "outputs": [],
   "source": [
    "def eval_model(y_test, y_predict):\n",
    "    # Binarize the output prediction vector\n",
    "    y_predict[y_predict <= 0.5] = 0\n",
    "    y_predict[y_predict > 0.5] = 1\n",
    "    # Build the confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_predict)\n",
    "    # Assign the true/false negative/positive\n",
    "    TN = cm[0,0]\n",
    "    TP = cm[1,1]\n",
    "    FN = cm[1,0]\n",
    "    FP = cm[0,1]\n",
    "    # Calculate accuracy, precision, recall, and F1 scores\n",
    "    acc = (TN + TP) / (TN + TP + FN + FP)\n",
    "    prec = TP / (TP + FP)\n",
    "    rec = TP / (TP + FN)\n",
    "    f1 = 2 * (prec * rec) / (prec + rec)\n",
    "    return acc, prec, rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T18:11:31.670190Z",
     "start_time": "2023-10-05T18:11:31.654482700Z"
    }
   },
   "outputs": [],
   "source": [
    "def binarize(n):\n",
    "    if n <= 0.5:\n",
    "        n = 0\n",
    "    elif n > 0.5:\n",
    "        n = 1\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T18:11:32.020597300Z",
     "start_time": "2023-10-05T18:11:31.670190Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 1ms/step - loss: 0.3610 - accuracy: 0.8439\n",
      "57/57 [==============================] - 0s 565us/step\n",
      "Accuracy: 0.8438888888888889\n",
      "Precision 0.7195767195767195\n",
      "Recall 0.37362637362637363\n",
      "F1 0.49186256781193494\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Load the model and run it on the test data set\n",
    "Take the results from the test data set and evaluate them with the eval_model function for specified eval metrics\n",
    "\"\"\"\n",
    "new_model1 = keras.models.load_model('saved_models/model-ann-11-5-4-1.keras')\n",
    "results = new_model1.evaluate(X_test_scaled, y_test)\n",
    "y_predict1 = new_model1.predict(X_test_scaled)\n",
    "a, p, r, f = eval_model(y_test, y_predict1)\n",
    "print(\"Accuracy: {}\".format(a))\n",
    "print(\"Precision {}\".format(p))\n",
    "print(\"Recall {}\".format(r))\n",
    "print(\"F1 {}\".format(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T18:11:32.087775Z",
     "start_time": "2023-10-05T18:11:32.023557100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "Predicted value for known data: 0 \n",
      "Known value: 0\n",
      "The model correctly predicted the 'Exited' value\n",
      "\n",
      "Unknown 'Exited' status predicted value: 0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Use the model to predict the value for a single known test set element and the single unknown test element set\n",
    "Also binarize the output for easy comparison\n",
    "\"\"\"\n",
    "predict_known_x = new_model1.predict(known_test_x)\n",
    "predict_unknown_x = new_model1.predict(unknown_test_x)\n",
    "predict_known_x = binarize(predict_known_x)\n",
    "predict_unknown_x = binarize(predict_unknown_x)\n",
    "print(\"Predicted value for known data: {} \\nKnown value: {}\".format(predict_known_x, known_test_y))\n",
    "if predict_known_x == known_test_y:\n",
    "    print(\"The model correctly predicted the 'Exited' value\\n\")\n",
    "else:\n",
    "    print(\"The model did not correctly predict the 'Exited' value\\n\")\n",
    "print(\"Unknown 'Exited' status predicted value: {}\".format(predict_unknown_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Our model has correctly predicted our output for the known element from the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second ANN Architecture\n",
    "\n",
    "![Display second ANN architecture](figs/nn-2.png)\n",
    "\n",
    "* Input layer will still have 11 units as the dimension of training set (i.e, number of columns = 11).\n",
    "* Hidden-layer-1: 8 neurons, with relu activation\n",
    "* Hidden-layer-2: 8 neurons, with relu activation,\n",
    "* Hidden-layer-3: 8 neurons, with relu activation,\n",
    "* Output-layer: 1 neuron with sigmoid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T18:11:40.418947900Z",
     "start_time": "2023-10-05T18:11:32.087775Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.6046 - accuracy: 0.6831\n",
      "Epoch 2/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4715 - accuracy: 0.7989\n",
      "Epoch 3/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4413 - accuracy: 0.8022\n",
      "Epoch 4/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.8085\n",
      "Epoch 5/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4180 - accuracy: 0.8143\n",
      "Epoch 6/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4099 - accuracy: 0.8199\n",
      "Epoch 7/25\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4027 - accuracy: 0.8235\n",
      "Epoch 8/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.3960 - accuracy: 0.8275\n",
      "Epoch 9/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.3904 - accuracy: 0.8269\n",
      "Epoch 10/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.3849 - accuracy: 0.8286\n",
      "Epoch 11/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.3799 - accuracy: 0.8317\n",
      "Epoch 12/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.3736 - accuracy: 0.8410\n",
      "Epoch 13/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.3675 - accuracy: 0.8483\n",
      "Epoch 14/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.3621 - accuracy: 0.8493\n",
      "Epoch 15/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.3579 - accuracy: 0.8517\n",
      "Epoch 16/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.3535 - accuracy: 0.8518\n",
      "Epoch 17/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.3504 - accuracy: 0.8543\n",
      "Epoch 18/25\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3482 - accuracy: 0.8551\n",
      "Epoch 19/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.3468 - accuracy: 0.8556\n",
      "Epoch 20/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.3447 - accuracy: 0.8576\n",
      "Epoch 21/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.3425 - accuracy: 0.8576\n",
      "Epoch 22/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.3427 - accuracy: 0.8583\n",
      "Epoch 23/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.3410 - accuracy: 0.8589\n",
      "Epoch 24/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.3398 - accuracy: 0.8600\n",
      "Epoch 25/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.3394 - accuracy: 0.8600\n"
     ]
    }
   ],
   "source": [
    "# Build the second model with the required specifications\n",
    "model2 = keras.Sequential()\n",
    "model2.add(layers.Dense(8, activation='relu', input_shape=(11,)))\n",
    "model2.add(layers.Dense(8, activation='relu'))\n",
    "model2.add(layers.Dense(8, activation='relu'))\n",
    "model2.add(layers.Dense(1, activation='sigmoid'))\n",
    "model2.compile(optimizer='adam', loss = 'binary_crossentropy', metrics=['accuracy'])\n",
    "model2.fit(X_train_scaled, y_train, epochs=25)\n",
    "model2.save('saved_models/model-ann-11-8-8-8-1.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T18:11:40.566021200Z",
     "start_time": "2023-10-05T18:11:40.418947900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 566us/step\n",
      "Accuracy: 0.8538888888888889\n",
      "Precision 0.6980392156862745\n",
      "Recall 0.489010989010989\n",
      "F1 0.5751211631663974\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Load the model and run it on the test data set\n",
    "Take the results from the test data set and evaluate them with the eval_model function for specified eval metrics\n",
    "\"\"\"\n",
    "new_model2 = keras.models.load_model('saved_models/model-ann-11-8-8-8-1.keras')\n",
    "y_predict2 = new_model2.predict(X_test_scaled)\n",
    "a, p, r, f = eval_model(y_test, y_predict2)\n",
    "print(\"Accuracy: {}\".format(a))\n",
    "print(\"Precision {}\".format(p))\n",
    "print(\"Recall {}\".format(r))\n",
    "print(\"F1 {}\".format(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T18:11:40.629876700Z",
     "start_time": "2023-10-05T18:11:40.562663600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Predicted value for known data: 0 \n",
      "Known value: 0\n",
      "The model correctly predicted the 'Exited' value\n",
      "\n",
      "Unknown 'Exited' status predicted value: 0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Use the model to predict the value for a single known test set element and the single unknown test element set\n",
    "Also binarize the output for easy comparison\n",
    "\"\"\"\n",
    "predict_known_x = new_model2.predict(known_test_x)\n",
    "predict_unknown_x = new_model2.predict(unknown_test_x)\n",
    "predict_known_x = binarize(predict_known_x)\n",
    "predict_unknown_x = binarize(predict_unknown_x)\n",
    "print(\"Predicted value for known data: {} \\nKnown value: {}\".format(predict_known_x, known_test_y))\n",
    "if predict_known_x == known_test_y:\n",
    "    print(\"The model correctly predicted the 'Exited' value\\n\")\n",
    "else:\n",
    "    print(\"The model did not correctly predict the 'Exited' value\\n\")\n",
    "print(\"Unknown 'Exited' status predicted value: {}\".format(predict_unknown_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Our model has correctly predicted our output for the known element from the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third ANN Architecture\n",
    "\n",
    "![Display third ANN architecture](figs/nn-3.png)\n",
    "\n",
    "* Input layer will still have 11 units as the dimension of training set (i.e, number of columns = 11).\n",
    "* Hidden-layer-1: 8 neurons, with relu activation\n",
    "* Hidden-layer-2: 4 neurons, with relu activation,\n",
    "* Hidden-layer-3: 2 neurons, with relu activation,\n",
    "* Output-layer: 1 neuron with sigmoid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-05T18:11:49.233004200Z",
     "start_time": "2023-10-05T18:11:40.629876700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.5429 - accuracy: 0.7962\n",
      "Epoch 2/25\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.7962\n",
      "Epoch 3/25\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7962\n",
      "Epoch 4/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4266 - accuracy: 0.7962\n",
      "Epoch 5/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4198 - accuracy: 0.7962\n",
      "Epoch 6/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4130 - accuracy: 0.7962\n",
      "Epoch 7/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.4054 - accuracy: 0.7962\n",
      "Epoch 8/25\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3980 - accuracy: 0.7962\n",
      "Epoch 9/25\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3921 - accuracy: 0.7962\n",
      "Epoch 10/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.3871 - accuracy: 0.8338\n",
      "Epoch 11/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.3831 - accuracy: 0.8406\n",
      "Epoch 12/25\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3797 - accuracy: 0.8429\n",
      "Epoch 13/25\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3766 - accuracy: 0.8449\n",
      "Epoch 14/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.3749 - accuracy: 0.8451\n",
      "Epoch 15/25\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3728 - accuracy: 0.8467\n",
      "Epoch 16/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.3708 - accuracy: 0.8485\n",
      "Epoch 17/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.3691 - accuracy: 0.8490\n",
      "Epoch 18/25\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3671 - accuracy: 0.8496\n",
      "Epoch 19/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.3654 - accuracy: 0.8526\n",
      "Epoch 20/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.3638 - accuracy: 0.8529\n",
      "Epoch 21/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.3626 - accuracy: 0.8562\n",
      "Epoch 22/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.3614 - accuracy: 0.8540\n",
      "Epoch 23/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.3606 - accuracy: 0.8564\n",
      "Epoch 24/25\n",
      "225/225 [==============================] - 0s 1ms/step - loss: 0.3597 - accuracy: 0.8558\n",
      "Epoch 25/25\n",
      "225/225 [==============================] - 0s 2ms/step - loss: 0.3588 - accuracy: 0.8581\n"
     ]
    }
   ],
   "source": [
    "# Build the third model with the required specifications\n",
    "model3 = keras.Sequential()\n",
    "model3.add(layers.Dense(8, activation='relu', input_shape=(11,)))\n",
    "model3.add(layers.Dense(4, activation='relu'))\n",
    "model3.add(layers.Dense(2, activation='relu'))\n",
    "model3.add(layers.Dense(1, activation='sigmoid'))\n",
    "model3.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model3.fit(X_train_scaled, y_train, epochs=25)\n",
    "model3.save('saved_models/model-ann-11-8-4-2-1.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T18:11:49.392475300Z",
     "start_time": "2023-10-05T18:11:49.233004200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 853us/step\n",
      "Accuracy: 0.8527777777777777\n",
      "Precision 0.7180616740088106\n",
      "Recall 0.4478021978021978\n",
      "F1 0.5516074450084603\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Load the model and run it on the test data set\n",
    "Take the results from the test data set and evaluate them with the eval_model function for specified eval metrics\n",
    "\"\"\"\n",
    "new_model3 = keras.models.load_model('saved_models/model-ann-11-8-4-2-1.keras')\n",
    "y_predict3 = new_model3.predict(X_test_scaled)\n",
    "a, p, r, f = eval_model(y_test, y_predict3)\n",
    "print(\"Accuracy: {}\".format(a))\n",
    "print(\"Precision {}\".format(p))\n",
    "print(\"Recall {}\".format(r))\n",
    "print(\"F1 {}\".format(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T18:11:49.472325Z",
     "start_time": "2023-10-05T18:11:49.392475300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Predicted value for known data: 0 \n",
      "Known value: 0\n",
      "The model correctly predicted the 'Exited' value\n",
      "\n",
      "Unknown 'Exited' status predicted value: 0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Use the model to predict the value for a single known test set element and the single unknown test element set\n",
    "Also binarize the output for easy comparison\n",
    "\"\"\"\n",
    "predict_known_x = new_model2.predict(known_test_x)\n",
    "predict_unknown_x = new_model2.predict(unknown_test_x)\n",
    "predict_known_x = binarize(predict_known_x)\n",
    "predict_unknown_x = binarize(predict_unknown_x)\n",
    "print(\"Predicted value for known data: {} \\nKnown value: {}\".format(predict_known_x, known_test_y))\n",
    "if predict_known_x == known_test_y:\n",
    "    print(\"The model correctly predicted the 'Exited' value\\n\")\n",
    "else:\n",
    "    print(\"The model did not correctly predict the 'Exited' value\\n\")\n",
    "print(\"Unknown 'Exited' status predicted value: {}\".format(predict_unknown_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Our model has correctly predicted our output for the known element from the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T18:11:49.498418300Z",
     "start_time": "2023-10-05T18:11:49.472325Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      3861\n",
      "CreditScore          571.0\n",
      "Geography           France\n",
      "Gender              Female\n",
      "Age                   33.0\n",
      "Tenure                   9\n",
      "Balance          102017.25\n",
      "NumOfProducts            2\n",
      "HasCrCard                0\n",
      "IsActiveMember           0\n",
      "EstimatedSalary  128600.49\n"
     ]
    }
   ],
   "source": [
    "print(known_test_inspect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T18:11:49.536173100Z",
     "start_time": "2023-10-05T18:11:49.488409800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     1080\n",
      "CreditScore         549.0\n",
      "Geography           Spain\n",
      "Gender             Female\n",
      "Age                  24.0\n",
      "Tenure                  9\n",
      "Balance               0.0\n",
      "NumOfProducts           2\n",
      "HasCrCard               1\n",
      "IsActiveMember          1\n",
      "EstimatedSalary  14406.41\n"
     ]
    }
   ],
   "source": [
    "print(unknown_test_inspect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Conclusions around classification\n",
    "From these two specific examples, it looks like what these two data elements have in common are that they are both females, both have credit scores in the mid 500's, purchased the same number of products, are both under the age of 40, and both have a tenure of 9\n",
    "Without drawing too many conclusions from limited data, it looks like women under 40 with lower credit scores may be more likely to be classified as 0 for 'Exited' in the model.  These two data samples have many differences, especially when it comes to their financial balances and salaries."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
